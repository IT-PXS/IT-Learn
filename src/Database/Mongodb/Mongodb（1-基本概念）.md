---
title: Mongodb（1-基本概念）
tag: Mongodb
category: 数据库
description: MongoDB是一种流行的NoSQL数据库，采用面向文档的数据模型。其核心概念中，“文档”是基本单位，以类似JSON的BSON格式存储。“集合”是文档的分组，相当于关系型数据库中的“表”。它模式自由、支持动态查询，非常适合处理大规模、非结构化的数据。
date: 2025-11-15 22:38:34
---

## 主要概念

### 数据库（database）

一个仓库，可以存放集合，MongoDB 中多个文档组成集合，多个集合组成数据库。

一个 MongoDB 实例可以承载多个数据库。它们之间可以看作相互独立，每个数据库都有独立的权限控制。在磁盘上，不同的数据库存放在不同的文件中。

MongoDB 中存在以下系统数据库：

1. Admin 数据库：一个权限数据库，如果创建用户的时候将该用户添加到 admin 数据库中，那么该用户就自动继承了所有数据库的权限。
2. Local 数据库：这个数据库永远不会被复制，可以用来存储本地单台服务器的任意集合。
3. Config 数据库：当 MongoDB 使用分片模式时，config 数据库在内部使用，用于保存分片的信息。

### 集合（collection）

类似于数组，可以存放文档。集合就是一组文档，类似于关系数据库中的表。

### 文档（document）

文档数据库中的最小单位，存储和操作的内容都是文档

`MongoDB` 中的记录是一个文档，它是由字段和值对组成的数据结构。多个键及其关联的值有序地放在一起就构成了文档。
`MongoDB` 文档类似于 `JSON` 对象。字段的值可以包括其他文档，数组和文档数组。

![](Mongodb（1-基本概念）/1.png)

## 应用场景

1. 社交场景：使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。

2. 游戏场景：使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、高效率存储和访问。

3. 物流场景：使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来

4. 物联网场景：使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。

5. 视频直播：使用 MongoDB 存储用户信息、点赞互动信息等。

这些应用场景中，数据操作方面的共同特点是：

- 数据量大
- 写入操作频繁（读写都很频繁）
- 价值较低的数据，对事务性要求不高


## JSON 与 BSON 的区别

BSON 是一种类 json 的一种二进制形式的存储格式，简称 Binary JSON，它和 JSON 一样，支持内嵌的文档对象和数组对象，但是 BSON 有 JSON 没有的一些数据类型，如 Date 和 BinData 类型。

与 JSON 的区别：

1. 更快的遍历速度

对 JSON 格式来说，太大的 JSON 结构会导致数据遍历非常慢。在 JSON 中，要跳过一个文档进行数据读取，需要对此文档进行扫描才行，需要进行麻烦的数据结构匹配，比如括号的匹配，而 BSON 对 JSON 的一大改进就是，它会将 JSON 的每一个元素的长度存在元素的头部，这样你只需要读取到元素长度就能直接 seek 到指定的点上进行读取了。

2. 操作更简易

对 JSON 来说，数据存储是无类型的，比如你要修改基本一个值，从 9 到 10，由于从一个字符变成了两个，所以可能其后面的所有内容都需要往后移一位才可以。而使用 BSON，你可以指定这个列为数字列，那么无论数字从 9 长到 10 还是 100，我们都只是在存储数字的那一位上进行修改，不会导致数据总长变大。当然，在 MongoDB 中，如果数字从整形增大到长整型，还是会导致数据总长变大的。

3. 增加了额外的数据类型

JSON 是一个很方便的数据交换格式，但是其类型比较有限。BSON 在其基础上增加了“byte array”数据类型。这使得二进制的存储不再需要先 base64 转换后再存成 JSON。大大减少了计算开销和数据大小。
但是，在有的时候， BSON 相对 JSON 来说也并没有空间上的优势，比如对{“field”: 7}，在 JSON 的存储上 7 只使用了一个字节，而如果用 BSON，那就是至少 4 个字节（32 位）

## 数据类型

### 数字

`shell` 默认使用 `64` 位浮点型数值，如下：

```shell
db.sang_collec.insert({x:3.1415926})
db.sang_collec.insert({x:3})
```

对于整型值，我们可以使用 `NumberInt` 或者 `NumberLong` 表示，如下：

```shell
db.sang_collec.insert({x:NumberInt(10)})
db.sang_collec.insert({x:NumberLong(12)})
```

### 字符串

```shell
db.sang_collec.insert({x:"hello MongoDB!"})
```

### 数组

```shell
db.sang_collec.insert({x:[1,2,3,4,new Date()]})
```

### 日期

`MongoDB` 支持 `Date` 类型的数据，可以直接 `new` 一个 `Date` 对象，如下：

```shell
db.sang_collec.insert({x:new Date()})
```

### 内嵌文档

```shell
db.sang_collect.insert({name:"三国演义",author:{name:"罗贯中",age:99}});
```

## 复制

### 什么是副本集？

| 角色      | 作用                                                         |
| --------- | ------------------------------------------------------------ |
| Primary   | 主节点，负责处理客户端请求，并将写请求记录在 oplog。         |
| Secondary | 从节点，负责从主节点同步数据，可以负责数据的读取的负载均衡 当主节点挂掉后，secondary 可以接管从而变为 Primary 节点。 |
| Arbiter   | 仲裁节点只能参与投票，不能成为 Primary，并且不从 Primary 同步数据。 当复制集为偶数时，最好加入一个 Arbiter 节点，以提升复制集的可用性。 比如你部署了 2 个节点的复制集，1 个 primary，1 个 Secondary，任意接地那党纪，复制集将不能提供服务，因为无法选举出 Primary，这时可以给复制集添加一个 Arbiter 节点，即使有节点宕机仍能选出 Primary 节点。 |
| Priority0 | Priority0 节点的选举优先级为 0，不能被选举为 Primary，但可以从主节点同步数据和参与主节点选举时投票。 |
| Vote0     | MongoDB3.0 里，复制集成员最多 50 个，参与 Primary 选举投票的成员最多 7 个，其他成员的 vote 属性必须设置为 0，即不参与投票。 |
| Hidden    | Hidden 节点不能被选举为主节点，即 Priority 必须为 0，并且对应用不可见。 因 Hidden 节点不会接受 Driver 的请求，可使用 Hidden 节点做一些数据备份，离线计算的任务，不会影响复制集的服务。 |
| Delayed   | Delayed 节点必须是 Hidden 节点，并且其数据落后与 Primary 一段时间（可自行配置，比如落后 1h）因 Delayed 节点的数据比 Primary 落后一段时间，当错误或者无效的数据写入 Primary 时，可通过 Delayed 节点的数据来恢复到之前的时间点。 |

副本集是一组维护相同数据集的 `mongod` 实例。副本集包含多个数据承载节点和一个可选的仲裁节点。在数据承载节点中，只有一个主节点，其他被为从节点。

副本集的最低推荐配置是具有三个数据承载节点的三节点副本集：一个 主节点和两个从节点。在某些情况下（例如您有一个主节点和一个从节点，但成本限制禁止添加另一个从节点），您可以选择包括仲裁节点。仲裁节点参与选举 ，但不持有数据（即不提供数据冗余）。

注意：每个副本集节点必须属于且只属于一个副本集。副本集节点不能属于多个副本集。

主节点会接收所有写入操作。副本集只能有一个可以使用写关注（write concern）级别对写入请求进行确认的主节点；尽管在某些情况下，另一 mongod 实例可能会暂时将自身视为主节点。主节点在其操作日志（即 oplog）中记录对其数据集的所有更改。

![](Mongodb（1-基本概念）/2.svg)

从节点复制主节点的 oplog，并将这些操作应用于其数据集，以便从节点的数据集反映主节点的数据集状态。如果主节点不可用，则某个符合条件的从节点将进行选举，以将自己选举为新的主节点

![](Mongodb（1-基本概念）/3.svg)

在某些情况下（例如存在一个主节点和一个从节点，但由于成本有限无法再添加另一个从节点），您可以选择将一个 `mongod` 实例作为仲裁节点添加到副本集中。仲裁节点参与选举，但不持有数据（即不提供数据冗余）

仲裁节点将永远是仲裁节点，而在选举期间，主节点可能被降级成为从节点，从节点可能变为主节点。

![](Mongodb（1-基本概念）/4.svg)

### 自动故障转移

副本集成员每两秒向彼此发送一次心跳（网络探测（ping））。如果心跳在 10 秒内未返回，其他成员会将违规成员标记为不可访问。

副本集拥有稳定的主节点后，选举算法将“尽最大努力”尝试让具有最高可用 `priority` 的从节点发起选举。成员优先级影响选举的时间和结果；具有较高优先级的从节点比具有较低优先级的从节点相对更早地发起选举，并且也更有可能获胜。但是，即使有更高优先级的从节点可用，也可以在短时间内将优先级较低的实例选为主节点。副本集成员继续发起选举，直到可用的最高优先级成员成为主节点。

当主节点在超过配置的 `electionTimeoutMillis` 时间段（默认 10 秒）内未与副本集中的其他节点通信时，一个符合条件的从节点将发起选举，并提名自己成为新的主节点。集群将尝试完成新主节点的选举并恢复其正常运转。

![](Mongodb（1-基本概念）/5.svg)

在成功完成选举之前，副本集无法处理写操作。如果将读取查询配置为当主节点离线时在从节点上运行，那么副本集可以继续为读取查询提供服务。

假设采用默认 `replica configuration settings`（副本配置设置），那么集群选举新的主节点之前的平均时间通常不应超过 12 秒。这包括将主节点标记为不可用以及召集和完成选举所需的时间。可以通过修改 `settings.electionTimeoutMillis` 复制配置选项来调整该时间段。

### 读取偏好

默认情况下，客户端从主节点读取；但是，客户端可以指定读取偏好以向从节点发送读取操作。

![](Mongodb（1-基本概念）/6.svg)

| 读取偏好模式         | 说明                                                         |
| :------------------- | :----------------------------------------------------------- |
| `primary`            | 默认模式。从当前副本集主节点读取的所有操作。包含读操作的分布式事务必须使用读取偏好 `primary`。给定事务中的所有操作必须路由至同一节点。 |
| `primaryPreferred`   | 在大多数情况下，操作将从主节点读取，但如果主节点不可用，则操作将从从节点 m-secondary) 成员读取。 |
| `secondary`          | 所有操作均会从副本集的辅助成员中读取。                       |
| `secondaryPreferred` | 操作通常从副本集的从节点成员读取数据。如果副本集只有一个主节点成员，并且没有其他成员，则操作将从主节点成员读取数据。 |
| `nearest`            | 根据指定的延迟阈值，从符合条件的随机副本集成员读取操作，无论该成员是主节点成员还是从节点成员。 该操作在计算延迟时会考虑以下因素：`localThresholdMS` 连接字符串选项 maxStalenessSeconds 读取偏好选项任何指定的标签集列表 |

## 分片

### 角色

![](Mongodb（1-基本概念）/7.svg)

MongoDB 分片集群中共有三种角色

1. Shard 角色（或称为分片服务器）： 这是 MongoDB 分片集群中的数据节点，用于存储实际的数据块。在实际生产环境中，一个 Shard 角色可以由几台机器组成一个副本集（Replica Set）来承担，以防止主机单点故障，保证数据的高可用性和完整性。Shard 角色可以是一个副本集，也可以是单独的一台服务器。
2. Config Server 角色（或称为配置服务器）： 这类角色主要用来保存 MongoDB 分片集群的元数据信息，包括各个分片包含了哪些数据的信息，以及数据块的分布信息等。Config Server 角色通常由一个独立的 mongod 进程来运行，并且为了保证其高可用性，通常会将其运行为一个副本集。它不需要太多的存储空间，因为保存的只是数据的分布表。
3. Router 角色（或称为路由服务器、mongos）： 这是 MongoDB 分片集群中的前端路由，客户端由此接入，让整个集群看上去像单一数据库。Router 角色主要用来接收客户端的读写请求，并将请求路由到相应的分片上进行处理。为了使得 Router 角色的高可用，通常会用多个节点来组成 Router 高可用集群。Router 角色通常由 mongos 实例来运行。

以上三种角色共同协作，实现了 MongoDB 的分片集群功能，使得 MongoDB 能够支持大规模的数据存储和高并发的读写操作。

### 处理流程

分片集群中，数据读写时的流程大致如下：

1. 客户端发送请求：客户端通过 MongoDB 的驱动程序连接到 Router 角色（mongos 实例）。客户端发送读写请求到 Router，请求中包含了要操作的数据库、集合以及具体的 CRUD（增删改查）操作。
2. Router 路由请求：Router 接收到客户端的请求后，会根据请求中的元数据信息（如数据库名、集合名和查询条件等），查询 Config Server 来获取数据的分片信息。Config Server 返回相关的分片信息给 Router，告诉它应该将数据路由到哪个 Shard 上进行处理。
3. Router 转发请求：Router 根据从 Config Server 获取的分片信息，将客户端的请求转发到相应的 Shard 上。如果请求涉及多个 Shard 上的数据（如跨分片的查询），Router 可能会将请求拆分成多个子请求，并分别发送到相关的 Shard 上进行处理。
4. Shard 处理请求：Shard 接收到 Router 转发的请求后，会在本地执行相应的 CRUD 操作。如果是写操作（如插入、更新、删除），Shard 会在本地进行数据变更，并将变更结果返回给 Router；如果是读操作（如查询），Shard 会查询本地存储的数据，并将查询结果返回给 Router。
5. Router 汇总结果：如果请求涉及多个 Shard 上的数据，Router 会等待所有 Shard 返回结果后，对结果进行汇总和排序等操作（如果需要的话），然后将最终的结果返回给客户端。
6. 客户端接收结果：客户端通过 MongoDB 的驱动程序接收到 Router 返回的结果，完成一次数据读写操作。

需要注意的是，MongoDB 分片集群中的 Router、Config Server 和 Shard 之间的通信是通过 MongoDB 的内部协议进行的，而客户端与 Router 之间的通信则是通过 MongoDB 的驱动程序和标准的 MongoDB 协议进行的。此外，为了保证数据的一致性和可用性，MongoDB 分片集群还提供了复制集（Replica Set）和自动故障切换等机制。

### Chunk

在一个 shard server 内部，MongoDB 会把数据分为 chunks，每个 chunk 代表这个 shard server 内部一部分数据。chunk 的产生，会有以下两个用途：

1. Splitting：当一个 chunk 的大小超过配置中的 chunk size 时，MongoDB 的后台进程会把这个 chunk 切分成更小的 chunk，从而避免 chunk 过大的情况
2. Balancing：在 MongoDB 中，balancer 是一个后台进程，负责 chunk 的迁移，从而均衡各个 shard server 的负载，系统初始 1 个 chunk，chunk size 默认值 64M，生产库上选择适合业务的 chunk size 是最好的。mongoDB 会自动拆分和迁移 chunks。

分片集群的数据分布（shard 节点）

1. 使用 chunk 来存储数据
2. 集群搭建完成之后，默认开启一个 chunk，大小是 64M，
3. 存储需求超过 64M，chunk 会进行分裂，如果单位时间存储需求很大，设置更大的 chunk
4. chunk 会被自动均衡迁移。

chunksize 的选择：

1. 小的 chunksize：数据均衡是迁移速度快，数据分布更均匀。数据分裂频繁，路由节点消耗更多资源。
2. 大的 chunksize：数据分裂少。数据块移动集中消耗 IO 资源。通常 100-200M

### 分片键的约束

ShardKey 必须是一个索引。非空集合须在 ShardCollection 前创建索引；空集合 ShardCollection 自动创建索引

1. 4.4 版本之前：

- ShardKey 大小不能超过 512 Bytes；
- 仅支持单字段的哈希分片键；
- Document 中必须包含 ShardKey；
- ShardKey 包含的 Field 不可以修改。

2. 4.4 版本之后:

- ShardKey 大小无限制；
- 支持复合哈希分片键；
- Document 中可以不包含 ShardKey，插入时被当 做 Null 处理；
- 为 ShardKey 添加后缀 refineCollectionShardKey 命令，可以修改 ShardKey 包含的 Field；

而在 4.2 版本之前，ShardKey 对应的值不可以修改；4.2 版本之后，如果 ShardKey 为非_id 字段， 那么可以修改 ShardKey 对应的值。

### 数据均衡

一种理想的情况是，所有加入的分片都发挥了相当的作用，包括提供更大的存储容量，以及读写访问性能。因此，为了保证分片集群的水平扩展能力，业务数据应当尽可能地保持均匀分布。这里的均匀性包含以下两个方面：

1. 所有的数据应均匀地分布于不同的 chunk 上。
2. 每个分片上的 chunk 数量尽可能是相近的。

#### 手动均衡 

可以在初始化集合时预分配一定数量的 chunk（仅适用于哈希分片），比如给 10 个分片分配 1000 个 chunk，那么每个分片拥有 100 个 chunk。另一种做法则是，可以通过 splitAt、moveChunk 命令进行手动切分、迁移。

#### 自动均衡

开启 MongoDB 集群的自动均衡功能。均衡器会在后台对各分片的 chunk 进行监控，一旦发现了不均衡状态就会自动进行 chunk 的搬迁以达到均衡。其中，chunk 不均衡通常来自于两方面的因素：

- 在没有人工干预的情况下，chunk 会持续增长并产生分裂（split），而不断分裂的结果就会出现数量上的不均衡；
- 在动态增加分片服务器时，也会出现不均衡的情况。自动均衡是开箱即用的，可以极大简化集群的管理工作。

MongoDB 的数据均衡器运行于 Primary Config Server（配置服务器的主节点）上，而该节点也同时会控制 chunk 数据的搬迁流程。

![](Mongodb（1-基本概念）/8.png)

流程说明：

1. 分片 shard0 在持续的业务写入压力下，产生了 chunk 分裂。
2. 分片服务器通知 Config Server 进行元数据更新。
3. Config Server 的自动均衡器对 chunk 分布进行检查，发现 shard0 和 shard1 的 chunk 数差异达到了阈值，向 shard0 下发 moveChunk 命令以执行 chunk 迁移。
4. shard0 执行指令，将指定数据块复制到 shard1。该阶段会完成索引、chunk 数据的复制，而且在整个过程中业务侧对数据的操作仍然会指向 shard0；所以，在第一轮复制完毕之后，目标 shard1 会向 shard0 确认是否还存在增量更新的数据，如果存在则继续复制。
5. shard0 完成迁移后发送通知，此时 Config Server 开始更新元数据库，将 chunk 的位置更新为目标 shard1。在更新完元数据库后并确保没有关联 cursor 的情况下，shard0 会删除被迁移的 chunk 副本。
6. Config Server 通知 mongos 服务器更新路由表。此时，新的业务请求将被路由到 shard1。

