---
title: MySQL（3-事务和日志）
tags: MySQL
categories: 数据库
cover: /img/index/mysql.png
top_img: /img/index/mysql.png
published: false
abbrlink: 63240
date: 2024-11-22 22:38:34
description:
---

## Redis 集群模式（Cluster）

### 出现背景

![](Redis（5-集群模式）\6.png)

在某些场景下，单实例存 Redis 缓存会存在的几个问题

1. 写并发：Redis 单实例读写分离可以解决读操作的负载均衡，但对于写操作，仍然是全部落在了 master 节点上面，在海量数据高并发场景，一个节点写数据容易出现瓶颈，造成 master 节点的压力上升
2. 海量数据的存储压力：单实例 Redis 本质上只有一台 master 作为存储，如果面对海量数据的存储，一台 Redis 的服务器就应付不过来了，而且数据量太大意味着持久化成本高，严重时可能会阻塞服务器，造成服务请求成功率下降，降低服务的稳定性

### 基本概念

Redis 集群是一个可以在多个 Redis 节点之间进行数据共享的设施（installation）。

Redis 集群不支持那些需要同时处理多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的行为。

Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。

Redis 集群提供了以下两个好处：

- 将数据自动切分（split）到多个节点的能力。
- 当集群中的一部分节点失效或者无法进行通讯时， 仍然可以继续处理命令请求的能力。

### 作用

![](Redis（5-集群模式）\7.png)

1. Redis 集群模式实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的 master 节点上面，从而解决了海量数据的存储问题
2. Redis 集群采用去中心化的思想，没有中心节点的说法，对于客户端来说，整个集群可以看出是一个整体，可以连接任意一个节点进行操作，就像操作单一 Redis 实例一样，不需要任何代理中间件，当客户端操作的 key 没有分配到该 node 上，Redis 会返回转向指令，指向正确的 node
3. Redis 内置了高可用机制，支持 N 个 Master 节点，每隔 master 节点都可以挂载多个 slave 节点，当 master 节点挂掉时，集群会提升他的某个 slave 节点作为新的 master 节点

### 客户端和服务端

Redis 集群中的节点有以下责任：

- 持有键值对数据。
- 记录集群的状态，包括键到正确节点的映射（mapping keys to right nodes）。
- 自动发现其他节点，识别工作不正常的节点，并在有需要时，在从节点中选举出新的主节点。

为了执行以上列出的任务， 集群中的每个节点都与其他节点建立起了“集群连接（cluster bus）”， 该连接是一个 TCP 连接， 使用二进制协议进行通讯。

节点之间使用 Gossip 协议 来进行以下工作：

- 传播（propagate）关于集群的信息，以此来发现新的节点。
- 向其他节点发送 `PING` 数据包，以此来检查目标节点是否正常运作。
- 在特定事件发生时，发送集群信息。

除此之外， 集群连接还用于在集群中发布或订阅信息。

因为集群节点不能代理（proxy）命令请求， 所以客户端应该在节点返回 `-MOVED` 或者 `-ASK` 转向（redirection）错误时， 自行将命令请求转发至其他节点。

因为客户端可以自由地向集群中的任何一个节点发送命令请求， 并可以在有需要时根据转向错误所提供的信息将命令转发至正确的节点， 所以在理论上来说，客户端是无须保存集群状态信息的。

不过， 如果客户端可以将键和节点之间的映射信息保存起来， 可以有效地减少可能出现的转向次数， 籍此提升命令执行的效率。

### 节点通信

在 Redis 集群中，不同的节点之间采用 gossip 协议进行通信，节点之间通讯的目的是为了维护节点之间的元数据信息。这些元数据就是每个节点包含哪些数据，是否出现故障，通过 gossip 协议，达到最终数据的一致性。

gossip 协议，是基于流行病传播方式的节点或者进程之间信息交换的协议。原理就是在不同的节点间不断地通信交换信息，一段时间后，所有的节点就都有了整个集群的完整信息，并且所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，但只要这些节可以通过网络连通，最终他们的状态就会是一致的。Gossip 协议最大的好处在于，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。

Redis 集群中节点的通信过程如下：

1. 集群中每个节点都会单独开一个 TCP 通道，用于节点间彼此通信。

2. 每个节点在固定周期内通过待定的规则选择几个节点发送 ping 消息

3. 接收到 ping 消息的节点用 pong 消息作为响应

使用 gossip 协议的优点在于将元数据的更新分散在不同的节点上面，降低了压力；但是缺点就是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。另外，由于 gossip 协议对服务器时间的要求较高，时间戳不准确会影响节点判断消息的有效性。而且节点数量增多后的网络开销也会对服务器产生压力，同时结点数太多，意味着达到最终一致性的时间也相对变长，因此官方推荐最大节点数为 1000 左右。

**gossip 协议的常见类型**

gossip 协议常见的消息类型包含： ping、pong、meet、fail 等等。

1. meet：主要用于通知新节点加入到集群中，通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。
2. ping：用于交换节点的元数据。每个节点每秒会向集群中其他节点发送 ping 消息，消息中封装了自身节点状态还有其他部分节点的状态数据，也包括自身所管理的槽信息等等。

* 因为发送 ping 命令时要携带一些元数据，如果很频繁，可能会加重网络负担。因此，一般每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。

* 如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长导致信息严重滞后。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。

* 每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 （总节点数 - 2）个其它节点的信息。

3. pong：ping 和 meet 消息的响应，同样包含了自身节点的状态和集群元数据信息。
4. fail：某个节点判断另一个节点 fail 之后，向集群所有节点广播该节点挂掉的消息，其他节点收到消息后标记已下线。

由于 Redis 集群的去中心化以及 gossip 通信机制，Redis 集群中的节点只能保证最终一致性。例如当加入新节点时(meet)，只有邀请节点和被邀请节点知道这件事，其余节点要等待 ping 消息一层一层扩散。除了 Fail 是立即全网通知的，其他诸如新节点、节点重上线、从节点选举成为主节点、槽变化等，都需要等待被通知到，也就是 Gossip 协议是最终一致性的协议。

**meet 命令的实现**

![](Redis（5-集群模式）\17.png)

1. 节点 A 会为节点 B 创建一个 clusterNode 结构，并将该结构添加到自己的 clusterState.nodes 字典里面。
2. 节点 A 根据 CLUSTER MEET 命令给定的 IP 地址和端口号，向节点 B 发送一条 MEET 消息。
3. 节点 B 接收到节点 A 发送的 MEET 消息，节点 B 会为节点 A 创建一个 clusterNode 结构，并将该结构添加到自己的 clusterState.nodes 字典里面。
4. 节点 B 向节点 A 返回一条 PONG 消息。
5. 节点 A 将受到节点 B 返回的 PONG 消息，通过这条 PONG 消息，节点 A 可以知道节点 B 已经成功的接收了自己发送的 MEET 消息。
6. 之后，节点 A 将向节点 B 返回一条 PING 消息。
7. 节点 B 将接收到的节点 A 返回的 PING 消息，通过这条 PING 消息节点 B 可以知道节点 A 已经成功的接收到了自己返回的 PONG 消息，握手完成。
8. 之后，节点 A 会将节点 B 的信息通过 Gossip 协议传播给集群中的其他节点，让其他节点也与节点 B 进行握手，最终，经过一段时间后，节点 B 会被集群中的所有节点认识。

### 节点属性

每个节点在集群中都有一个独一无二的 ID ， 该 ID 是一个十六进制表示的 160 位随机数， 在节点第一次启动时由 `/dev/urandom` 生成。

节点会将它的 ID 保存到配置文件， 只要这个配置文件不被删除， 节点就会一直沿用这个 ID 。

节点 ID 用于标识集群中的每个节点。 一个节点可以改变它的 IP 和端口号， 而不改变节点 ID 。 集群可以自动识别出 IP/端口号的变化， 并将这一信息通过 Gossip 协议广播给其他节点知道。

以下是每个节点都有的关联信息， 并且节点会将这些信息发送给其他节点：

- 节点所使用的 IP 地址和 TCP 端口号。
- 节点的标志（flags）。
- 节点负责处理的哈希槽。
- 节点最近一次使用集群连接发送 `PING` 数据包（packet）的时间。
- 节点最近一次在回复中接收到 `PONG` 数据包的时间。
- 集群将该节点标记为下线的时间。
- 该节点的从节点数量。
- 如果该节点是从节点的话，那么它会记录主节点的节点 ID 。 如果这是一个主节点的话，那么主节点 ID 这一栏的值为 `0000000` 。

### 节点握手

节点总是应答（accept）来自集群连接端口的连接请求， 并对接收到的 `PING` 数据包进行回复， 即使这个 `PING` 数据包来自不可信的节点。

然而， 除了 `PING` 之外， 节点会拒绝其他所有并非来自集群节点的数据包。

要让一个节点承认另一个节点同属于一个集群， 只有以下两种方法：

- 一个节点可以通过向另一个节点发送 `MEET` 信息， 来强制让接收信息的节点承认发送信息的节点为集群中的一份子。 一个节点仅在管理员显式地向它发送 `CLUSTER MEET ip port` 命令时， 才会向另一个节点发送 `MEET` 信息。
- 如果一个可信节点向另一个节点传播第三者节点的信息， 那么接收信息的那个节点也会将第三者节点识别为集群中的一份子。 也即是说， 如果 A 认识 B ， B 认识 C ， 并且 B 向 A 传播关于 C 的信息， 那么 A 也会将 C 识别为集群中的一份子， 并尝试连接 C 。

这意味着如果我们将一个/一些新节点添加到一个集群中， 那么这个/这些新节点最终会和集群中已有的其他所有节点连接起来。

### 节点失效检测

以下是节点失效检查的实现方法：

- 当一个节点向另一个节点发送 PING 命令， 但是目标节点未能在给定的时限内返回 PING 命令的回复时， 那么发送命令的节点会将目标节点标记为 `PFAIL` （possible failure，可能已失效）。

  等待 PING 命令回复的时限称为“节点超时时限（node timeout）”， 是一个节点选项（node-wise setting）。

- 每次当节点对其他节点发送 PING 命令的时候， 它都会随机地广播三个它所知道的节点的信息， 这些信息里面的其中一项就是说明节点是否已经被标记为 `PFAIL` 或者 `FAIL` 。

- 当节点接收到其他节点发来的信息时， 它会记下那些被其他节点标记为失效的节点。 这称为失效报告（failure report）。

- 如果节点已经将某个节点标记为 `PFAIL` ， 并且根据节点所收到的失效报告显式， 集群中的大部分其他主节点也认为那个节点进入了失效状态， 那么节点会将那个失效节点的状态标记为 `FAIL` 。

- 一旦某个节点被标记为 `FAIL` ， 关于这个节点已失效的信息就会被广播到整个集群， 所有接收到这条信息的节点都会将失效节点标记为 `FAIL` 。

简单来说， 一个节点要将另一个节点标记为失效， 必须先询问其他节点的意见， 并且得到大部分主节点的同意才行。

因为过期的失效报告会被移除， 所以主节点要将某个节点标记为 `FAIL` 的话， 必须以最近接收到的失效报告作为根据。

在以下两种情况中， 节点的 `FAIL` 状态会被移除：

- 如果被标记为 `FAIL` 的是从节点， 那么当这个节点重新上线时， `FAIL` 标记就会被移除。

  保持（retaning）从节点的 `FAIL` 状态是没有意义的， 因为它不处理任何槽， 一个从节点是否处于 `FAIL` 状态， 决定了这个从节点在有需要时能否被提升为主节点。

- 如果一个主节点被打上 `FAIL` 标记之后， 经过了节点超时时限的四倍时间， 再加上十秒钟之后， 针对这个主节点的槽的故障转移操作仍未完成， 并且这个主节点已经重新上线的话， 那么移除对这个节点的 `FAIL` 标记。

在第二种情况中， 如果故障转移未能顺利完成， 并且主节点重新上线， 那么集群就继续使用原来的主节点， 从而免去管理员介入的必要。

### 集群状态检测

每当集群发生配置变化时（可能是哈希槽更新，也可能是某个节点进入失效状态）， 集群中的每个节点都会对它所知道的节点进行扫描（scan）。

一旦配置处理完毕， 集群会进入以下两种状态的其中一种：

- `FAIL` ： 集群不能正常工作。 当集群中有某个节点进入失效状态时， 集群不能处理任何命令请求， 对于每个命令请求， 集群节点都返回错误回复。
- `OK` ： 集群可以正常工作， 负责处理全部 `16384` 个槽的节点中， 没有一个节点被标记为 `FAIL` 状态。

这说明即使集群中只有一部分哈希槽不能正常使用， 整个集群也会停止处理任何命令。

不过节点从出现问题到被标记为 `FAIL` 状态的这段时间里， 集群仍然会正常运作， 所以集群在某些时候， 仍然有可能只能处理针对 `16384` 个槽的其中一个子集的命令请求。

以下是集群进入 `FAIL` 状态的两种情况：

1. 至少有一个哈希槽不可用，因为负责处理这个槽的节点进入了 `FAIL` 状态。
2. 集群中的大部分主节点都进入下线状态。当大部分主节点都进入 `PFAIL` 状态时，集群也会进入 `FAIL` 状态。

第二个检查是必须的， 因为要将一个节点从 `PFAIL` 状态改变为 `FAIL` 状态， 必须要有大部分主节点进行投票表决， 但是， 当集群中的大部分主节点都进入失效状态时， 单凭一个两个节点是没有办法将一个节点标记为 `FAIL` 状态的。

因此， 有了第二个检查条件， 只要集群中的大部分主节点进入了下线状态， 那么集群就可以在不请求这些主节点的意见下， 将某个节点判断为 `FAIL` 状态， 从而让整个集群停止处理命令请求。

### 从节点选举

一旦某个主节点进入 `FAIL` 状态， 如果这个主节点有一个或多个从节点存在， 那么其中一个从节点会被升级为新的主节点， 而其他从节点则会开始对这个新的主节点进行复制。

新的主节点由已下线主节点属下的所有从节点中自行选举产生， 以下是选举的条件：

- 这个节点是已下线主节点的从节点。
- 已下线主节点负责处理的槽数量非空。
- 从节点的数据被认为是可靠的， 也即是， 主从节点之间的复制连接（replication link）的断线时长不能超过节点超时时限（node timeout）乘以 `REDIS_CLUSTER_SLAVE_VALIDITY_MULT` 常量得出的积。

如果一个从节点满足了以上的所有条件， 那么这个从节点将向集群中的其他主节点发送授权请求， 询问它们， 是否允许自己（从节点）升级为新的主节点。

如果发送授权请求的从节点满足以下属性， 那么主节点将向从节点返回 `FAILOVER_AUTH_GRANTED` 授权， 同意从节点的升级要求：

- 发送授权请求的是一个从节点， 并且它所属的主节点处于 `FAIL` 状态。
- 在已下线主节点的所有从节点中， 这个从节点的节点 ID 在排序中是最小的。
- 这个从节点处于正常的运行状态： 它没有被标记为 `FAIL` 状态， 也没有被标记为 `PFAIL` 状态。

一旦某个从节点在给定的时限内得到大部分主节点的授权， 它就会开始执行以下故障转移操作：

- 通过 `PONG` 数据包（packet）告知其他节点， 这个节点现在是主节点了。
- 通过 `PONG` 数据包告知其他节点， 这个节点是一个已升级的从节点（promoted slave）。
- 接管（claiming）所有由已下线主节点负责处理的哈希槽。
- 显式地向所有节点广播一个 `PONG` 数据包， 加速其他节点识别这个节点的进度， 而不是等待定时的 `PING` / `PONG` 数据包。

所有其他节点都会根据新的主节点对配置进行相应的更新，特别地：

- 所有被新的主节点接管的槽会被更新。
- 已下线主节点的所有从节点会察觉到 `PROMOTED` 标志， 并开始对新的主节点进行复制。
- 如果已下线的主节点重新回到上线状态， 那么它会察觉到 `PROMOTED` 标志， 并将自身调整为现任主节点的从节点。

在集群的生命周期中， 如果一个带有 `PROMOTED` 标识的主节点因为某些原因转变成了从节点， 那么该节点将丢失它所带有的 `PROMOTED` 标识。

### 哈希槽算法

1. 普通 hash 算法：将 key 使用 hash 算法计算之后，按照节点数量来取余，即 hash(key)%N，优点就是比较简单，但是扩容或者摘除节点时需要根据映射关系计算，会导致数据重新迁移
2. 一致性 hash 算法：为每一个节点分配一个 token，构成一个哈希环，查找时先根据 key 计算 hash 值，然后顺时针找到第一个大于等于该哈希值的 token 节点，优点是在加入和删除节点时只影响相邻的两个节点，缺点是加减节点会造成部分数据无法命中，所以一般用于缓存，而且用于节点量大的情况下，扩容一般增加一倍节点保障数据负载均衡
3. 哈希槽算法：Redis 集群中有 16384 个哈希槽（槽的范围为 0-16383），将不同的哈希槽分布在不同的 Redis 节点上面进行管理，每个 Redis 节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会使用 CRC16 算法对 key 进行计算并对 16384 取模，得到的结果就是 key-value 所放入的槽，通过这个值去找到对应的槽所对应的 Redis 节点，然后直接到这个对应的节点进行存取操作

![](Redis（5-集群模式）\8.png)

+ 节点 Ａ 存储的哈希槽范围是：0 – 5500
+ 节点 Ｂ 存储的哈希槽范围是：5501 – 11000
+ 节点 Ｃ 存储的哈希槽范围是：11001 – 16384

哈希槽算法方便节点的添加和删除。例如：需要新增一个节点 D，只需要把 A、B、C 中的部分哈希槽移到 D 节点。如果在集群中删除 A 节点，只需要把 A 节点的哈希槽的数据移到 B 和 C 节点，当 A 节点的数据全部被移走后，A 节点就可以完全从集群中删除。因为把哈希槽从一个节点移到另一个节点是不需要停机的，所以增加或删除节点，或更改节点上的哈希槽，也是不需要停机的

### Redis 分区（分片）

分区可以让 Redis 管理更大的内存，Redis 将可以使用所有机器的内存，如果没有分区，最多只能使用一台机器的内存。分区使 Redis 的计算能力通过简单地增加计算机得到成倍提升，Redis 的网络带宽也会随着计算机和网卡的增加而成倍增长

**实现方式**

1. 客户端分区：把分片的逻辑放在 Redis 客户端实现（比如：jedis 已支持 Redis Sharding 功能，即 ShardedJedis），通过 Redis 客户端预先定义好的路由规则（一般采用固定的哈希算法），把不同的 key 写入到不同的节点上，然后再根据这个规则进行数据读取

<img src="Redis（5-集群模式）\14.png" style="zoom: 50%;" />

2. 代理辅助分区：指我们的客户端通过 Redis 协议把请求发送给代理，而不是直接发送给真正的 Redis 实例服务器，这个代理会确保我们的请求根据配置分区策略发送到正确的 Redis 实例上，并返回给客户端

<img src="Redis（5-集群模式）\15.png" style="zoom: 50%;" />

3. 查询路由：指可以把一个请求发送给一个随机的实例，这时实例会把该查询转发给正确的节点，通过客户端重定向（客户端的请求不用直接从一个实例转发到另一个实例，而是被重定向到正确的节点）

**缺点**

1. 不支持多个键的操作，比如：不能操作映射在两个 Redis 实例上的两个集合的交叉集
2. Redis 不支持多个键的事务
3. Redis 是以键来分区，因此不能使用单个大键对数据集进行分片，例如：一个非常大的有序集
4. 如果使用分区，数据的处理会变得复杂，比如：必须处理多个 RDB 和 AOF 文件，在多个实例和主机之间持久化数据
5. 添加和删除节点也会变得复杂，比如：通过在运行时添加和删除节点，Redis 集群通常支持透明地再均衡数据，但是其他系统像客户端分区或者代理分区的特性就不支持该特性

#### Redis cluster 数据分片

在 Redis 的 Cluster 集群模式中，使用了哈希槽（hash slot）的方式来进行数据分片，将整个数据集划分为 16384 个槽，每个节点负责部分槽。客户端访问数据时，先计算出数据对应的槽，然后直接连接到该槽所在的节点进行操作

![](Redis（5-集群模式）\16.png)

上图把 16384 个槽均匀分配给了三个节点，当然，如果各个节点机器的性能不一样，也可以用【cluster addslots】命令为每个节点自定义分配槽的数量。

在 Redis 的每个节点上，都有这么两个东西：

1. 槽（slot）：它的取值范围是 0~16384（2^14)。

2. cluster：可以理解为是一个集群管理的插件。

当我们存取 key 的时候，Redis 会根据 CRC16 算法得出一个结果，然后把结果对 16384 取模，这样就得到了一个在 0~16384 范围之间的哈希槽，通过这个值去找到对应负责该槽的节点，然后就可以进行存取操作了。

#### Redis 节点的增加和删除

无论是增加还是删除节点，redis cluster 都会让数据尽可能的均匀分布。比如，现在有三个节点：Redis1 [0,5460]，Redis2 [5461,10922]，Redis3 [10924,16383]。

这时增加了一台 Redis4，那么 cluster 就会从 1、2、3 的数据会迁移一部分到节点 4 上，实现 4 个节点数据均匀，这时每个节点的负责 16384/4 = 4096 个槽。

减少节点也同理，假设删除 Redis，那么 Redis4 节点上数据也会均匀地迁移到 1、2、3，删除后，现在每个节点负责的槽位是：16384/3 = 6128。

**扩容**

1. 客户端对目标节点发起准备导入槽数据的命令，让目标节点准备好导入槽数据。使用命令：cluster setslot {slot} importing {sourceNodeId}
2. 之后对源节点发起送命令，让源节点准备迁出对应的槽数据。使用命令：cluster setslot {slot} migrating {targetNodeId}
3. 此时源节点准备迁移数据了，在迁移之前把要迁移的数据获取出来。通过命令 cluster getkeysinslot {slot} {count}。Count 表示迁移的 Slot 的个数。
4. 然后在源节点上执行，migrate {targetIP} {targetPort} “” 0 {timeout} keys {keys} 命令，把获取的键通过流水线批量迁移到目标节点。
5. 重复 3 和 4 两步不断将数据迁移到目标节点。
6. 完成数据迁移到目标节点以后，通过 cluster setslot {slot} node {targetNodeId} 命令通知对应的槽被分配到目标节点，并且广播这个信息给全网的其他主节点，更新自身的槽节点对应表。

**收缩**

1. 迁移槽。
2. 忘记节点。通过命令 cluster forget {downNodeId} 通知其他的节点

#### 为什么是 16384 个槽呢？

Redis 集群共有 16384 个槽，每个 key 通过 CRC16 校验后取模来决定放置在哪个槽位上，但是为什么哈希槽的数量是 16384(2^14)个呢，CRC16 算法产生的 hash 是 16bit，该算法可以产生 2^16 = 65535 个值。

1. 浪费带宽：redis 节点需要发送一定数量的 ping 消息作为心跳包，如果槽位是 65535，那么根据公式 myslots【CLUSTER_SLOTS/8】，占用的空间为 65535/8/1024 = 8kb，而 16384/8/1024 = 2kb。
2. redis 的集群主节点基本不可能超过 1000 个：集群节点越多，心跳包的消息体携带的数据越多，如果超过 1000 个，也会导致网络拥堵，而 1000 个节点以内的 cluster 集群，16384 个槽位也足够用了。
3. 压缩比高：redis 主节点的配置信息中它所负责的哈希槽是通过 bitmap 的形式来保存的，在传输过程中会对 bitmap 压缩，但如果 bitmap 填充率 slots/N 很高的话（N 为节点数），bitmap 的压缩率就很低。如果节点少，而哈希槽数量多的话，bitmap 的压缩率就很低。

#### 为什么 Redis 用哈希槽而没用一致性哈希呢？

首先，Redis 哈希槽和一致性哈希，总的流程都是差不多的，都是两个阶段。

第一阶段是 hash 之后取模分片：

1. hash，hash 的核心就是保证数据不倾斜，或者说保证均匀分布。redis cluster 采用的是 CRC16 算法。
2. 取模，就是槽位的数量，redis cluster 集群有 16384(2^14)个槽位，而一致性哈希有 2^32 个槽位。

第二阶段是 node 映射：

1. redis cluster 哈希槽是静态映射（算到哪里是哪里）。

2. 一致性哈希是哈希环顺时针映射。

通过对比，我们可以得出结论：

1. 一致性哈希环顺时针映射优先考虑的是如何实现最少的节点数据发生数据迁移，当增加或移除节点，只有离新节点最近的节点会涉及到数据迁移。

2. redis cluster 哈希槽是静态映射，优先考虑的是如何实现数据均匀分布，当增加或移除节点时，所有的节点都会参与进来平摊压力。（我们搞集群的目的是啥？还不是单机容量不足，需要扩容多机组成集群，然后将数据尽可能的均匀分布吗）。

3. 同时，redis cluster 哈希槽静态映射还有一个优点，就是可以手动调整 slots 槽的分配

#### 客户端如何定位数据？

Redis 实例会把自己的哈希槽信息发送和它相连接的其他实例，来完成哈希槽分配信息的扩散，当实例相互连接后，每个实例就有所有哈希槽的映射关系了

客户端收到哈希槽信息后，会把哈希槽信息缓存在本地，当客户端请求键值对时，先先计算键所在的哈希槽，然后就可以给相应的实例发送请求了，当客户端向节点请求键值对时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己

1. 如果键所在的槽刚好指派给了当前节点，那么节点会直接执行这个命令
2. 如果没有指派给当前节点，那么节点会向客户端返回一个 MOVED 错误，然后重定向到正确的节点，并再次发送之前待执行的命令

![](Redis（5-集群模式）\9.png)

**计算键属于哪个槽**

节点通过以下算法来定义 key 属于哪个槽：crc16(key, keylen)&0x3FFFF

1. crc16：用于计算 key 的 CRC-16 校验和
2. 0x3FFF：换算成 10 进制是 16383
3. &0x3FFF：用于计算出一个介于 0~16383 之间的整数作为 key 的槽号

通过 CLUSTER KEYSLOT \< KEY > 命令可以查看 key 属于哪个槽

**判断槽是否由当前节点负责处理**

当节点计算出 key 所属的槽 i 之后，节点会判断槽 i 是否被指派了自己，每个节点会维护一个 slots 数组，节点通过检查 slots [i]，判断槽 i 是否由自己负责：

1. 如果说 slots [i] 对应的节点是当前节点的话，那么说明槽 i 由当前节点负责，节点可以执行客户端发送的命令
2. 如果说 slots [i] 对应的不是当前节点，节点会根据 slots [i] 所指向的节点向客户端返回 MOVED 错误，指引客户端转到正确的节点

#### MOVED 错误

格式：MOVED \< slot >\< ip >: \< port >

1. slot：键所在的槽
2. ip：负责处理槽 slot 节点的 ip
3. port：负责处理槽 slot 节点的 port

比如：MOVED 10086 127.0.0.1:7002，表示客户端请求的键值对所在的哈希槽 10086，实际是在 127.0.0.1:7002 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了，这样一来，客户端就可以直接和 7002 连接，并发送操作请求了，同时，客户端还会更新本地缓存，将该槽与 Redis 实例对应关系更新正确

注意：集群模式的 redis-cli 客户端在接收到 MOVED 错误时，并不会打印出 MOVED 错误，而是根据 MOVED 错误自动进行节点转向，所以我们是看不到节点返回的 MOVED 错误的，而使用单机模式的 redis-cli 客户端可以打印 MOVED 错误

#### 重新分片

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

1. 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽
2. 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍

重新分片可以在线进行，即重新分片的过程中，集群不需要下线

![](Redis（5-集群模式）\10.png)

添加一个节点 7004，然后通过重新分片，将原本指派给节点 7003 的槽 15001~槽 16383 改为指派给 7004

在重新分片的期间，源节点向目标节点迁移槽的过程中，可能会出现这样一种情况：如果某个槽的数据比较多，部分迁移到新实例，还有一部分没有迁移咋办？在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息

#### ASK 错误

如果客户端向目标节点发送一个与数据库键有关的命令，并且这个命令要处理的键正好属于被迁移的槽时：

1. 源节点会先在自己的数据库里查找指定的键，如果找到的话，直接执行命令
2. 如果源节点没有找到，那么这个键就有可能已经迁移到了目标节点，源节点就会向客户端发送一个 ASK 错误，指引客户端转向目标节点，并再次发送之前要执行的命令

![](Redis（5-集群模式）\11.png)

节点 7003 正在向 7004 迁移槽 16383，这个槽包含 hello 和 world，其中键 hello 还留在节点 7003，而 world 已经迁移到 7004，向节点 7003 发送关于 hello 命令，会直接执行

```java
127.0.0.1:7003> GET "hello"
"you get the key 'hello'"
```

向节点 7003 发送 world，那么客户端就会被重定向到 7004，客户端在接收到 ASK 错误之后，先发送一个 ASKING 命令，然后再发送 GET "world" 命令

```java
127.0.0.1:7003> GET "world"
-> (error) ASK 16383 127.0.0.1:7004
```

#### ASK 和 MOVED 的区别

1. ASK 错误和 MOVED 错误都会导致客户端重定向
2. MOVED 错误代表槽的负责权已经从一个节点转移到了另一个节点：在客户端收到关于槽 i 的 MOVED 错误之后，客户端每次遇到关于槽 i 的命令请求时，都可以直接将命令请求发送至 MOVED 错误指向的节点，因为该节点就是目前负责槽 i 的节点
3. ASK 只是两个节点迁移槽的过程中的一种临时措施：在客户端收到关于槽 i 的 ASK 错误之后，客户端只会在接下来的一次命令请求中将关于槽 i 的命令请求发送到 ASK 错误指向的节点，但是，如果客户端再次请求槽 i 中的数据，它还是会给原来负责槽 i 的节点发送请求
4. ASK 命令的作用只是让客户端能给新实例发送一次请求，而且也不会更新客户端缓存的哈希槽分配信息，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例

### 数据一致性

Redis 集群不保证数据的强一致性（strong consistency）： 在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。

使用异步复制（asynchronous replication）是 Redis 集群可能会丢失写命令的其中一个原因

- 客户端向主节点 B 发送一条写命令。
- 主节点 B 执行写命令，并向客户端返回命令回复。
- 主节点 B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3 。

Redis 集群另外一种可能会丢失命令的情况是， 集群出现网络分裂， 并且一个客户端与至少包括一个主节点在内的少数（minority）实例被孤立。

举个例子， 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， 而 A1 、B1 、C1 分别为三个主节点的从节点， 另外还有一个客户端 Z1 。

假设集群中发生网络分裂， 那么集群可能会分裂为两方， 大多数（majority）的一方包含节点 A 、C 、A1 、B1 和 C1 ， 而少数（minority）的一方则包含节点 B 和客户端 Z1 。

在网络分裂期间， 主节点 B 仍然会接受 Z1 发送的写命令：

- 如果网络分裂出现的时间很短， 那么集群会继续正常运行；
- 但是， 如果网络分裂出现的时间足够长， 使得大多数一方将从节点 B1 设置为新的主节点， 并使用 B1 来代替原来的主节点 B ， 那么 Z1 发送给主节点 B 的写命令将丢失。

## 出现问题

### 数据迁移问题

Redis 集群可以进行节点的动态扩容缩容，这一过程目前还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。而 Redis 为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态，对于小 Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。

### 带宽消耗问题

Redis 集群是无中心节点的集群架构，依靠 Gossip 协议协同自动化修复集群的状态，但 goosip 有消息延时和消息冗余的问题，在集群节点数量过多的时候，goosip 协议通信会消耗大量的带宽，主要体现在以下几个方面：

1. 消息发送频率：跟 cluster-node-timeout 密切相关，当节点发现与其他节点的最后通信时间超过 cluster-node-timeout/2 时会直接发送 ping 消息

2. 消息数据量：每个消息主要的数据占用包含：slots 槽数组（2kb）和整个集群 1/10 的状态数据

3. 节点部署的机器规模：机器的带宽上限是固定的，因此相同规模的集群分布的机器越多，每台机器划分的节点越均匀，则整个集群内整体的可用带宽越高

集群带宽消耗主要分为：读写命令消耗+Gossip 消息消耗，因此搭建 Redis 集群需要根据业务数据规模和消息通信成本做出合理规划：

1. 在满足业务需求的情况下尽量避免大集群，同一个系统可以针对不同业务场景拆分使用若干个集群。
2. 适度提供 cluster-node-timeout 降低消息发送频率，但是 cluster-node-timeout 还影响故障转移的速度，因此需要根据自身业务场景兼顾二者平衡
3. 如果条件允许尽量均匀部署在更多机器上，避免集中部署。如果有 60 个节点的集群部署在 3 台机器上每台 20 个节点，这是机器的带宽消耗将非常严重

### Pub/Sub 广播问题

集群模式下内部对所有 publish 命令都会向所有节点进行广播，加重带宽负担，所以集群应该避免频繁使用 Pub/sub 功能

### 集群倾斜

集群倾斜是指不同节点之间数据量和请求量出现明显差异，这种情况将加大负载均衡和开发运维的难度。因此需要理解集群倾斜的原因

1. 数据倾斜：

- 节点和槽分配不均
- 不同槽对应键数量差异过大
- 集合对象包含大量元素
- 内存相关配置不一致

2. 请求倾斜：

合理设计键，热点大集合对象做拆分或者使用hmget代替hgetall避免整体读取


## Redis 集群脑裂

### 什么是集群脑裂？

一般来说是指一个分布式系统中有两个子集，然后每个子集都有一个自己的大脑（Leader/Master）。那么整个分布式系统就会存在多个大脑了，而且每个都认为自己是正常的，这就会导致数据不一致或重复写入的问题。

在 Redis 集群中，每个节点的部署方式一般都是【一主多从】，主节点提供写操作，从节点提供读操作。如果主节点此时发生网络故障，与从节点断开连接了，但主节点与客户端是正常的，客户端依旧向主节点写入数据。

这时哨兵节点发现主节点有故障失联了，于是哨兵节点就会从从节点选出一个 leader 作为新主节点，这时脑裂就出现了。

突然这时原主节点网络好了，然而此时故障转移已完毕，已经有新主节点了，那么原主节点就会降级为新主节点的从节点，新主节点会向所有实例发送 slave of 命令，让所有实例重新全量同步，在全量同步之前，从节点会先清空自己的数据，那么客户端在原主节点故障期间写入的数据就丢失了

![](Redis（5-集群模式）\12.png)

### 脑裂的发生

Redis 的脑裂问题可能发生在网络分区或者主节点出现问题的时候

1. 网络分区：网络故障或分区导致了不同子集之间的通信中断。Master、哨兵和 Slave 节点被分割为了两个网络，此时哨兵发现和 Master 连接不上，就会发起主从切换，选出一个新的 Master，这就出现了两个主节点（如上图）。
2. 主节点问题：主节点出现问题，导致不同的子集认为它们是正常的主节点。Master 出现问题，哨兵开始主从切换，但在切换过程中主节点又恢复了，这时候可能会导致一部分 slave 节点认为它是 Master，而另一部分新选出了一个 Master。

### 危害

1. 数据不一致：不同子集之间可能对同一数据进行不同的写入，导致数据不一致。
2. 重复写入：在脑裂问题解决后，不同子集可能尝试将相同的写操作应用到主节点上，导致数据重复。
3. 数据丢失：新选出来的 Matser 会向所有的实例发送 slave of 命令，让所有实例重新进行全量同步，在此之前会先清空实例上的数据，所以在主从切换期间，原 Matser 上执行的写命令也会被清空。

### 解决方法

脑裂的主要原因其实就是哨兵集群认为主节点出现 "假故障" 了，于是开始主从切换，选举出了新的主节点，这就导致短暂的出现了两个主节点。所以应对脑裂的解决办法应该是取限制原主库接收请求，Redis 提供了两个配置项

```tex
# 如果有少于 N 个从节点连接且滞后时间小于或等于 M 秒，主节点可以停止接受写入操作。
# 这些 N 个从节点需要处于“在线”状态。
# 滞后时间必须小于或等于指定值，以秒为单位，是从上次接收到的从节点ping的时间计算出来的，
# 通常每秒发送一次。
# 此选项不能保证 N 个副本会接受写入操作，但会限制在不足够的从节点可用时丢失写入的暴露窗口# 到指定的秒数。
# 例如，要求至少有 3 个滞后时间小于或等于 10 秒的从节点，请使用：
min-slaves-to-write 3
min-slaves-max-lag 10
```

1. min-slaves-to-write：主库能进行数据同步的最少从库数量。
2. min-slaves-max-lag：主从进行数据复制时，从库给主库发送 ACK 消息的最大延迟秒数。

这两项必须同时满足，不然主节点会禁止写入操作，这就解决了因脑裂导致数据丢失的问题

例如：我们把 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 10。如果 Master 节点因为某些原因挂了 12s，导致哨兵判断主节点客观下线，开始主从切换。同时，因为原 Master 宕机了 12s，没有一个（min-slaves-to-write）从节点与主节点之间的数据复制在 10s（min-slaves-max-lag）内，不满足配置要求，原 Master 就无法执行写操作了。

### 为什么不能彻底解决脑裂问题？

我们把 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 10，同时把 down-after-milliseconds 设置为 8s，也就是如果 8 秒连不上主节点，哨兵就会进行主从切换。

假设 Master 节点宕机 8s，哨兵会判为客观下线，开始主从切换，但是这个过程一共需要 5 秒。那如果主从切换过程中，主节点在第 9 秒恢复运行了，而 min-slaves-max-lag 10s 那么主节点还是可以写的。

那么在 9~12 秒期间原主节点还是可以接收客户端传的写命令并且执行，新主节点执行 slave of 命令后，这个期间写的数据就会丢失。

![](Redis（5-集群模式）\13.png)

## Hash 算法

### 渐进式 Rehash

Redis 通过链式哈希解决冲突：同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能可能变差，所以 Redis 为了追求快，使用了两个全局哈希表，用于 rehash 操作，增加现有的哈希桶数量，减少哈希冲突

![](Redis（5-集群模式）\8-1747745339292-1.png)

开始默认使用 hash 表 1 保存键值对数据，hash 表 2 此刻没有分配空间，当数据越来越多触发 rehash 操作，则执行以下操作：

1. 给 hash 表 2 分配更大的空间
2. 将 hash 表 1 的数据重新映射拷贝到 hash 表 2 中
3. 释放 hash 表 1 的空间

注意：将 hash 表 1 的数据重新映射到 hash 表 2 的过程中并不是一次性的，这样会造成 Redis 阻塞，无法提供服务。而是采用了渐进式 rehash，每次处理客户端请求的时候，先从 hash 表 1 中第一个索引开始，将这个为止的所有数据拷贝到 hash 表 2 中，就这样 rehash 分散到多次请求过程中，避免耗时阻塞

![](Redis（5-集群模式）\9-1747745339293-2.png)

在将数据拷贝至 Hash Table2 时，Hash Table1 仍然对客户端提供服务，当客户端访问 Hash Table1 时，Hash Table1 将索引位置为 1 的 Bucket1 中的 Entry 全部拷贝至 Hash Table2，如果没有找到则去 Hash Table2 查找。当客户端再一次访问 Hash Table1 时，Hash Table1 将索引位置为 2 的 Bucket2 中的 Entry 全部拷贝至 Hash Table2，再拷贝数据进 Hash Table2 的同时会对数据做重新的 Bucket 分配，从而减少 hash 冲突。当 Hash Table1 的元素都拷贝到 Hash Table2 时，Hash Table2 会顶替 Hash Table1 与客户端进行交互，此时 Hash Table1 被释放，等待下一次 Rehash 使用

### 一致性 hash

#### 产生原因

3 个机器节点，10 个数据的哈希值分别为 1、2、3、4......，使用的哈希函数为：hash(x)%3

1. 机器 0 上保存的数据为：3，6，9
2. 机器 1 上保存的数据为：1，4，7，10
3. 机器 2 上保存的数据为：2，5，8

当增加一台机器后，此时 n = 4，各个机器上存储的数据分别为

1. 机器 0 上保存的数据为：4，8
2. 机器 1 上保存的数据为：1，5，9
3. 机器 2 上保存的数据为：2，6，10
4. 机器 3 上保存的数据为：3，7

只有数据 1 和数据 2 没有移动，所以当集群中数据量很大时，采用一般的哈希函数，在节点数量动态变化的情况下会造成大量的数据迁移，导致网络通信压力的剧增，严重情况，还可能导致数据库宕机

#### 算法思想

将 hash 算法的值域映射成一个具有 2 的 32 次方个桶的空间中，即 0~（2 的 32 次方）-1 的数字空间，将这些数字头尾相连，组合成一个闭合的环形

假设现在有 4 个 redis 节点，那么这 4 个节点如何确定自己在环上的位置的呢？

将各个服务器进行一个哈希，具体可以选择服务器的 IP 或主机名作为关键字进行哈希(hash(ip))，这样每台机器就能确定其在哈希环上的位置。

<img src="Redis（5-集群模式）\10-1747745339293-7.png" style="zoom:67%;" />

那么 key 是如何分配的各个节点的呢？key 分配过程核心有两个阶段：

1. 进行 slot 槽位计算，每个 key 进行 hash 运算，被 hash 后的结果与 2^32 取模，获得 slot 槽位。
2. 在 hash 槽位环上，按顺时针去找到最近的 redis 节点，那么这个 key 将会被保存在这个节点上。

<img src="Redis（5-集群模式）\11-1747745339293-3.png" style="zoom:67%;" />

**增加节点**

当缓存集群的节点有所增加的时候，整个环形空间的映射仍然会保持一致性哈希的顺时针规则，所以有一小部分的 key 的归属会受到影响

<img src="Redis（5-集群模式）\12-1747745339293-8.png" style="zoom:67%;" />

**删除节点**

当缓存集群的节点有所减少的时候，整个环形空间的映射仍然会保持一致性哈希的顺时针规则，所以有一小部分的 key 的归属会受到影响。

这也是一致性哈希算法存在的最大问题：数据倾斜问题。

<img src="Redis（5-集群模式）\13-1747745339293-4.png" style="zoom:67%;" />

#### 雪崩效应

![](Redis（5-集群模式）\14-1747745339293-5.png)

当 B 节点宕机后，原本存储在 B 节点的 k1、k2 将会迁移到节点 C 上，这可能会导致很大的问题。如果 B 上存储的是热点数据，将数据迁移到 C 节点上，然后 C 需要承受 B+C 的数据，也承受不住，也挂了，然后继续 C、D 都挂了，这就造成了雪崩效应

#### 虚拟节点

为了解决节点太少而产生的数据分配不均衡的问题，也可能导致雪崩效应，一致性 hash 通过引入虚拟节点的方式做了优化。

虚拟节点：基于原来的物理节点映射出 N 个子节点，最后把所有的子节点映射到环形空间上

虚拟节点越多，分布越均匀，使用一致性 hash 算法+虚拟节点的情况下，缓存节点从 3 个变成 4 个，缓存失效率为 25%，而且每个节点都平均地承担了压力

<img src="Redis（5-集群模式）\15-1747745339293-6.png" style="zoom:67%;" />