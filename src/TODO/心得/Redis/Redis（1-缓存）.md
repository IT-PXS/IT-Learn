---
title: Redis（1-缓存）
series: Redis
tags: Redis
categories: 数据库
cover: /img/index/redis.png
top_img: /img/index/redis.png
published: false
abbrlink: 63240
date: 2024-11-22 22:38:34
description:
---

## 缓存穿透

指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透

**解决方法**

1. 缓存空对象：如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过 5 分钟

存在问题：

+ 空值做了缓存，意味着缓存中存了更多的键，需要更多的内存空间，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除
+ 缓存和存储的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如：过期时间设置为 5 分钟，如果此时存储添加了这个数据，那此段时间就会出现缓存和存储数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象

2. 布隆过滤器：将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截到，从而避免了对底层存储系统的查询压力

## 缓存击穿

一份热点数据，他的访问量非常大，在其缓存失效的瞬间，大量请求直达存储层，导致服务崩溃

**解决方法**

1. 永不过期：热点数据不设置过期时间，所以不会出现上述问题，这是“物理”上的永不过期。或者为每个数据设置逻辑过期时间，当发现该数据逻辑过期时，使用单独的线程重建缓存
2. 加互斥锁：对数据的访问加互斥锁，当一个线程访问该数据时，其他线程只能等待。这个线程访问过后，缓存中的数据将被重建，届时其他线程就可以直接从缓存中取值

## 缓存雪崩

如果缓存集中在一段时间内失效，所有的查询都落在数据库上，造成了缓存雪崩

**解决方法**

1. 加锁排队：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如，对某个 key 只允许一个线程查询数据和写缓存，其他线程等待
2. 数据预热：可以通过缓存 reload 机制，预先去更新缓存，在即将发生大并发访问前手动触发加载缓存不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀
3. 做二级缓存，或者双缓存策略：Cache1 为原始缓存，Cache2 为拷贝缓存，Cache1 失效时，可以访问 Cache2，Cache1 缓存失效时间设置为短期，Cache2 设置为长期
4. 在缓存的时候给过期时间加上一个随机值，这样就会大幅度地减少缓存在同一时间过期

如果是 Redis 故障宕机，则解决方法有：

1. 服务熔断或请求限流机制

服务熔断机制：暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务

请求限流机制：只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制

2. 构建 Redis 缓存高可靠集群

如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题

## 缓存倾斜

有一个超级热点数据存储在 Redis 集群的某一个结点上，导致大量的请求都访问 Redis 集群的某一个节点，导致这个节点宕机

**解决方案**

1. 给存放热点数据的节点搭建主从架构分担查询压力
2. 多级缓存（本地缓存、cdn、redis 等）
3. 将 key 根据一定的后缀名进行拆分，分散到多个阶段中，客户端请求的时候再根据一定规则计算得到一个固定的 key

## 缓存预热

指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据

如果不进行预热，那么 Redis 初始化状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中，对数据库造成流量的压力

**解决方案**

1. 数据量不大的时候，工程启动的时候进行加载缓存动作
2. 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新
3. 数据量太大的时候，优先保证热点数据进行提前加载到缓存

## 缓存降级

指当访问量剧增、服务出现问题（比如响应时间慢或者不响应）或者非核心服务影响到核心流程的性能时，即使是有损部分其他服务，仍然需要保证主服务可用，可以将其他次要访问的数据进行缓存降级，从而提升主服务的稳定性

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅，从而梳理出哪些必须誓死保护，哪些可以降级；比如可以参考日志级别设置预案：

1. 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级
2. 警告：有些服务在一段时间内成功率有波动（如在 95~100%之间），可以自动降级
3. 错误：比如可用率低于 90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阈值，此时可以根据情况自动降级或者人工降级
4. 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级

## 缓存淘汰策略

当写入数据将导致超出 maxmemory 限制时，Redis 会采用 maxmemory-policy 所指定的策略进行数据淘汰，该策略一共有以下 8 种选项：

| 策略            | 描述                                                 | 版本 |
| --------------- | ---------------------------------------------------- | ---- |
| noeviction      | 直接返回错误                                         |      |
| volatile-ttl    | 从设置了过期时间的键中，选择过期时间最小的键进行淘汰 |      |
| volatile-random | 从设置了过期时间的键中，随机选择键进行淘汰           |      |
| volatile-lru    | 从设置了过期时间的键中，使用 LFU 算法选择键进行淘汰    |      |
| volatile-lfu    | 从设置了过期时间的键中，使用 LFU 算法选择键进行淘汰    | 4.0  |
| allkeys-random  | 从所有的键中，随机选择键进行淘汰                     |      |
| allkeys-lru     | 从所有的键中，使用 LRU 算法选择键进行淘汰              |      |
| allkeys-lfu     | 从所有的键中，使用 LFU 算法选择键进行淘汰              | 4.0  |

1. volatile：代表从设置了过期时间的键中淘汰数据
2. allkeys：代表从所有的键中淘汰数据
3. ttl：代表过期时间最小的键
4. random：代表随机选择键
5. lru 和 lfu：分别代表采用 lru 算法和 lfu 算法来淘汰数据

### LRU

LRU（Least Recently Used）是按照最近最少使用原则来筛选数据，即最不常用的数据会被筛选出来

1. 标准 LRU：把所有的数据组成一个链表，表头和表尾分别标识 MRU 和 LRU 端，即最常使用端和最少使用端。刚被访问的数据会被移动到 MRU 端，而新增的数据也是刚被访问的数据，也会被移动到 MRU 端。当链表的空间被占满时，它会删除 LRU 端的数据
2. 近似 LRU：Redis 会记录每个数据的最近一次访问的时间戳（LRU）。Redis 执行写入操作时，若发现内存超出 maxmemory，就会执行一次近似 LRU 淘汰算法。近似 LRU 会随机采样 N 个 key，然后淘汰掉最旧的 key，若淘汰后内存依然超出限制，则继续采用淘汰。可以通过 maxmemory_samples 配置项，设置近似 LRU 每次采样的数据个数，该配置项的默认值为 5

LRU 算法的不足：若一个 key 很少被访问，只是刚刚偶尔被访问了一次，则它就被认为是热点数据，短时间内不会被淘汰

### LFU

LFU（Least Frequently Used）算法用于解决上述问题，LFU 是 Redis4 新增的淘汰策略，它根据 key 的最近访问频率进行淘汰。LFU 在 LRU 的基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略淘汰算法时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出内存。如果两个数据的访问次数相同，LFU 再比较这两个数据的访问时间，把访问时间更早的数据淘汰出内存

## 过期键删除策略

### 定时删除

每个设置过期时间的 key 都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的 CPU 资源去处理过期的数据，从而影响缓存的响应时间和吞吐量

### 惰性过期

只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。该策略可以最大化地节省 CPU 资源；却对内存非常不友好，极端情况可能出现大量的过期 key 没有再次被访问，从而不会被清除，占用大量内存

### 定期清除

每隔一定的时间，会扫描一定数量的数据库的 expires 字典中一定数量的 key，并清除其中已过期的 key。删除逻辑如下：

+ 从过期字典中随机选择 20 个 key
+ 删除这 20 个 key 中已过期的 key
+ 如果已过期 key 的比例超过 25%，则重复步骤 1

注意：Redis 中同时使用了惰性过期和定期删除两种策略，以求在合理使用 CPU 时间和避免内存浪费之前取得平衡

### 如何设计 Redis 的过期时间？

1. 热点数据不设置过期时间，使其达到“物理”上的永不过期，可以避免缓存击穿问题
2. 在设置过期时间时，可以附加一个随机数，避免大量的 key 同时过期，导致缓存雪崩

## 数据库与缓存双写一致性

### 更新与删除缓存对比

1. 更新缓存

* 优点：每次数据变化都及时更新缓存，所以查询时不容易出现未命中的情况
* 缺点：更新缓存的消耗比较大，如果数据需要经过复杂的计算再写入缓存，那么频繁地更新缓存就会影响服务器的性能，如果是写入数据频繁的业务场景，那么可能频繁的更新缓存时，却没有业务读取该数据

2. 删除缓存

* 优点：操作简单，无论更新操作是否复杂，都是将缓存中的数据直接删除
* 缺点：删除缓存后，下一次查询缓存会出现未命中，这时需要重新读取一次数据库

### 先更新数据库，后更新缓存（不使用）

缺点：

1. 当写操作十分频繁的情况下，可能用户根本就没有去读缓存数据就又频繁更新了，是很浪费性能的
2. 如果数据并不是直接写入缓存的，而是经过一系列计算再存入数据库的，那么频繁更新缓存同时还浪费了主业务服务器的性能
3. 并发更新数据库场景下，会将脏数据刷到缓存

解决方法：分布式锁，操作串行化

### 先更新缓存，后更新数据库（不使用）

缺点：如果先更新缓存成功，但是数据库更新失败，则肯定会造成数据不一致

### 先删除缓存，后更新数据库

该方案也会出问题，此时来了两个请求，请求 A（更新操作）和请求 B（查询操作）

操作步骤：

1. 请求 A 进行写操作，删除缓存
2. 请求 B 查询发现缓存不存在
3. 请求 B 去数据库查询得到旧值
4. 请求 B 将旧值写入缓存
5. 请求 A 将新值写入数据库

#### 延时双删

操作步骤：

1. 先淘汰缓存
2. 再写数据库（这两步和原来一样）
3. 休眠 1 秒，再次淘汰缓存，这么做可以将 1 秒内所造成的缓存脏数据再次删除，确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百 ms 即可

**读写分离**

![](Redis（1-缓存）/1.png)

如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差

此时来了两个请求，请求 A（更新操作）和请求 B（查询操作），操作流程如下：

1. 请求 A 更新操作，删除了 Redis
2. 请求主库进行更新操作，主库与从库进行同步数据的操作
3. 请求 B 查询操作，发现 Redis 中没有数据
4. 去从库中拿取数据
5. 此时同步数据还未完成，拿到的数据是旧数据

解决方法：如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询

![](Redis（1-缓存）/2.png)

**采用这种同步淘汰策略，吞吐量降低怎么办？**

将第二次删除作为异步的，自己起一个线程异步删除，这样写的请求就不用沉睡一段时间后了再返回，这么做会加大吞吐量。

**第二次删除, 如果删除失败怎么办？**

第二次删除失败，就会出现如下情形：

- 请求 A 进行写操作，删除缓存
- 请求 B 查询发现缓存不存在
- 请求 B 去数据库查询得到旧值
- 请求 B 将旧值写入缓存
- 请求 A 将新值写入数据库
- 请求 A 试图去删除请求 B 写入的缓存值，结果失败了。

如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。

#### 更新与读取操作异步串行化

**异步串行化**

1. 在系统内部维护 n 个内存队列，更新数据的时候，根据数据的唯一标识，将该操作路由之后，发送到其中一个 jvm 内部的内存队列中（对同一数据的请求发送到同一个队列）。
2. 读取数据的时候，如果发现数据不在缓存中，并且此时队列里有更新库存的操作，那么将重新进行【读取数据+更新缓存】的操作，根据唯一标识路由之后，也将发送到同一个 jvm 内部的内存队列中
3. 每个队列对应一个工作线程，每个工作线程串行地拿到相应的操作，然后一条一条地执行

这样的话，一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是还没完成更新的时候，如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作之后，然后同步等待缓存更新完成，再读库

**读操作去重**

多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果发现队列中已经有了该数据的更新缓存的请求了，那么就不用再放进去了，直接等待前面的更新操作请求完成即可，待那个队列对应的工作线程完成了上一个操作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从数据库中读取最新的值，然后写入缓存中

* 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；
* 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值

返回旧值不是又导致缓存和数据库不一致么？那至少可以减少这个情况发生，因为等待超时也不是每次都是，几率很小，如果超时了就直接读旧值，这时候仅仅是读库后返回而不放缓存

### 先更新数据库，后删除缓存（推荐）

操作步骤：

1. 缓存中 X 不存在（数据库 X = 1）
2. 线程 A 读取数据库，得到旧值（X = 1）
3. 线程 B 更新数据库（X = 2)
4. 线程 B 删除缓存
5. 线程 A 将旧值写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），也发生不一致。

这种情况理论来说是可能发生的，但概率很低，这是因为它必须满足 3 个条件：

1. 缓存刚好已失效
2. 读请求 + 写请求并发
3. 更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）

仔细想一下，条件 3 发生的概率其实是非常低的。因为写数据库一般会先加锁，所以写数据库，通常是要比读数据库的时间更长的。这么来看，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。

#### 重试机制

问题：更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了

解决方案就是利用消息队列进行删除的补偿，过程如下：

1. 请求 A 先对数据库进行更新操作
2. 在对 Redis 进行删除操作的时候发现报错，删除失败
3. 此时将 Redis 的 key 作为消息体发送到消息队列中
4. 系统接收到消息队列发送的消息后再次对 Redis 进行删除操作

![](Redis（1-缓存）/5.png)

缺点：会对业务代码造成大量的侵入，深深地耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后在 binlog 日志中我们都能找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作

拿 MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。

![](Redis（1-缓存）/6.png)